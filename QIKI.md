### ASSISTANT
# üìò QIKI Neural Engine - –ü–æ–ª–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è

## üìã –û–ø–∏—Å–∞–Ω–∏–µ

QIKI Neural Engine - —ç—Ç–æ –∫–æ–º–ø–∞–∫—Ç–Ω—ã–π, –±–µ–∑–æ–ø–∞—Å–Ω—ã–π –∏ CPU-–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤–æ–π –¥–≤–∏–∂–æ–∫ –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –≤ –∞–≥–µ–Ω—Ç–Ω—É—é —Å–∏—Å—Ç–µ–º—É QIKI. –†–µ–∞–ª–∏–∑—É–µ—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏—é "–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π" –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∞–≥–µ–Ω—Ç–∞ –∏ –∏–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç—Å—è –≤ —Ü–∏–∫–ª –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏–π —á–µ—Ä–µ–∑ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å `INeuralEngine`.

## üóÇÔ∏è –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

```
ne_qiki/
‚îú‚îÄ‚îÄ core/                          # –Ø–¥—Ä–æ –¥–≤–∏–∂–∫–∞
‚îÇ   ‚îú‚îÄ‚îÄ interfaces.py              # –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å INeuralEngine
‚îÇ   ‚îú‚îÄ‚îÄ feature_extractor.py       # –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
‚îÇ   ‚îú‚îÄ‚îÄ neural_engine_impl.py      # –†–µ–∞–ª–∏–∑–∞—Ü–∏—è NeuralEngineV1
‚îÇ   ‚îú‚îÄ‚îÄ proposal_evaluator.py      # –û—Ü–µ–Ω–∫–∞ –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
‚îÇ   ‚îú‚îÄ‚îÄ safety.py                  # –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å –∏ –∞–Ω—Ç–∏-—Ñ–ª–∞–ø–ø–∏–Ω–≥
‚îÇ   ‚îú‚îÄ‚îÄ calibration.py             # –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–Ω–∞—è –∫–∞–ª–∏–±—Ä–æ–≤–∫–∞
‚îÇ   ‚îú‚îÄ‚îÄ metrics.py                 # Prometheus-–º–µ—Ç—Ä–∏–∫–∏
‚îÇ   ‚îú‚îÄ‚îÄ nats_logger.py             # NATS-–ª–æ–≥–≥–µ—Ä
‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ models/                        # –ù–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã–µ –º–æ–¥–µ–ª–∏
‚îÇ   ‚îú‚îÄ‚îÄ ne_v1.py                   # GRU+MLP –º–æ–¥–µ–ª—å
‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ shared/                        # –û–±—â–∏–µ –º–æ–¥–µ–ª–∏ –¥–∞–Ω–Ω—ã—Ö
‚îÇ   ‚îú‚îÄ‚îÄ models.py                  # ActuatorCommand, Proposal
‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ configs/                       # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
‚îÇ   ‚îî‚îÄ‚îÄ config.example.yaml        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
‚îú‚îÄ‚îÄ schemas/                       # JSON-—Å—Ö–µ–º—ã
‚îÇ   ‚îú‚îÄ‚îÄ agent_context.schema.json  # –°—Ö–µ–º–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
‚îÇ   ‚îú‚îÄ‚îÄ action_catalog.schema.json # –°—Ö–µ–º–∞ –¥–µ–π—Å—Ç–≤–∏–π
‚îÇ   ‚îî‚îÄ‚îÄ safety.schema.yaml         # –°—Ö–µ–º–∞ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
‚îú‚îÄ‚îÄ api/                           # API
‚îÇ   ‚îî‚îÄ‚îÄ health_check.py            # Health-check API
‚îú‚îÄ‚îÄ benchmark/                     # –ë–µ–Ω—á–º–∞—Ä–∫–∏
‚îÇ   ‚îî‚îÄ‚îÄ onnx_benchmark.py          # –ë–µ–Ω—á–º–∞—Ä–∫ ONNX
‚îú‚îÄ‚îÄ datasets/                      # –†–∞–±–æ—Ç–∞ —Å –¥–∞—Ç–∞—Å–µ—Ç–∞–º–∏
‚îÇ   ‚îî‚îÄ‚îÄ jsonl_dataset.py           # –ó–∞–≥—Ä—É–∑—á–∏–∫ JSONL
‚îú‚îÄ‚îÄ examples/                      # –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
‚îÇ   ‚îî‚îÄ‚îÄ mock_inference.py          # –ü—Ä–∏–º–µ—Ä –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞
‚îú‚îÄ‚îÄ tests/                         # –Æ–Ω–∏—Ç-—Ç–µ—Å—Ç—ã
‚îÇ   ‚îú‚îÄ‚îÄ test_ne_v1_contract.py     # –ö–æ–Ω—Ç—Ä–∞–∫—Ç NeuralEngine
‚îÇ   ‚îú‚îÄ‚îÄ test_feature_extractor.py  # –¢–µ—Å—Ç –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ç–æ—Ä–∞
‚îÇ   ‚îú‚îÄ‚îÄ test_safety_shield.py      # –¢–µ—Å—Ç –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
‚îÇ   ‚îú‚îÄ‚îÄ test_proposal_evaluator.py # –¢–µ—Å—Ç –æ—Ü–µ–Ω—â–∏–∫–∞
‚îÇ   ‚îú‚îÄ‚îÄ test_nats_logger.py        # –¢–µ—Å—Ç NATS-–ª–æ–≥–≥–µ—Ä–∞
‚îÇ   ‚îú‚îÄ‚îÄ test_dataset_generator.py  # –¢–µ—Å—Ç –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞
‚îÇ   ‚îú‚îÄ‚îÄ test_terminal_dashboard.py # –¢–µ—Å—Ç —Ç–µ—Ä–º–∏–Ω–∞–ª—å–Ω–æ–≥–æ dashboard
‚îÇ   ‚îú‚îÄ‚îÄ test_neural_engine_dashboard_integration.py # –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Ç–µ—Å—Ç
‚îÇ   ‚îú‚îÄ‚îÄ test_global_logger.py      # –¢–µ—Å—Ç –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ –ª–æ–≥–≥–µ—Ä–∞
‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ tools/                         # –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã
‚îÇ   ‚îú‚îÄ‚îÄ terminal_dashboard.py      # –¢–µ—Ä–º–∏–Ω–∞–ª—å–Ω—ã–π dashboard
‚îÇ   ‚îú‚îÄ‚îÄ global_logger.py           # –ì–ª–æ–±–∞–ª—å–Ω—ã–π –ª–æ–≥–≥–µ—Ä
‚îÇ   ‚îú‚îÄ‚îÄ generate_dataset.py        # –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞
‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ monitoring/                    # –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
‚îÇ   ‚îú‚îÄ‚îÄ prometheus.yml             # –ö–æ–Ω—Ñ–∏–≥ Prometheus
‚îÇ   ‚îî‚îÄ‚îÄ dashboard.json             # Grafana –¥–∞—à–±–æ—Ä–¥
‚îú‚îÄ‚îÄ train_bc.py                    # –û–±—É—á–µ–Ω–∏–µ –∏ —ç–∫—Å–ø–æ—Ä—Ç ONNX
‚îú‚îÄ‚îÄ run_tests.py                   # –ï–¥–∏–Ω—ã–π —Ç–µ—Å—Ç-—Ä–∞–Ω–Ω–µ—Ä
‚îú‚îÄ‚îÄ Dockerfile                     # Docker-–æ–±—Ä–∞–∑
‚îú‚îÄ‚îÄ docker-compose.yml             # Docker Compose
‚îú‚îÄ‚îÄ requirements.txt               # –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
‚îî‚îÄ‚îÄ .github/
    ‚îî‚îÄ‚îÄ workflows/
        ‚îî‚îÄ‚îÄ ci.yml                 # CI Pipeline
```

## üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

### –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π

```bash
pip install -r requirements.txt
```

### –ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤

```bash
docker-compose up -d
```

### –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

```bash
python examples/mock_inference.py
```

### –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤

```bash
python run_tests.py
```

### –¢–µ—Ä–º–∏–Ω–∞–ª—å–Ω—ã–π dashboard

```bash
python tools/terminal_dashboard.py
```

## üß™ –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

### –û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã

| –ö–æ–º–ø–æ–Ω–µ–Ω—Ç | –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ |
|----------|------------|
| `INeuralEngine` | –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –≤ QIKI |
| `NeuralEngineV1` | –†–µ–∞–ª–∏–∑–∞—Ü–∏—è: –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è ‚Üí –º–æ–¥–µ–ª—å ‚Üí –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è |
| `NE_v1` | GRU(2√ó64) + MLP –≥–æ–ª–æ–≤—ã |
| `FeatureExtractor` | –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç `AgentContext` –≤ —Ç–µ–Ω–∑–æ—Ä |
| `SafetyShield` | –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å –∏ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç —Ñ–ª–∞–ø–ø–∏–Ω–≥ |
| `ProposalEvaluator` | –§–∏–ª—å—Ç—Ä—É–µ—Ç –∏ —Å–æ—Ä—Ç–∏—Ä—É–µ—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è |

### –ü–æ—Ç–æ–∫ –¥–∞–Ω–Ω—ã—Ö

```
AgentContext ‚Üí FeatureExtractor ‚Üí NE_v1 (GRU+MLP) ‚Üí Calibration ‚Üí Proposals ‚Üí 
SafetyShield ‚Üí ProposalEvaluator ‚Üí Decision
```

## üì¶ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

–§–∞–π–ª: `configs/config.example.yaml`

```yaml
window: 16
in_dim: 32
num_classes: 6
param_dim: 4
topk: 3
min_confidence: 0.55
time_budget_ms: 8
calibration:
  temperature: 1.2
action_catalog:
  actions:
    - name: HOLD_POSITION
      params:
        duration: [0.1, 5.0]
    - name: COOLING_BOOST
      params:
        intensity: [0.1, 1.0]
    - name: THROTTLE_DOWN
      params:
        level: [0.0, 1.0]
    - name: THROTTLE_UP
      params:
        level: [0.0, 1.0]
    - name: ROTATE_LEFT
      params:
        angle: [0.0, 3.14]
    - name: ROTATE_RIGHT
      params:
        angle: [0.0, 3.14]
safety:
  fsm_invariants:
    - ERROR_STATE
  bios_invariants:
    - bios_ok
```

## üîê –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å

### –†–µ–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ö–∞–Ω–∏–∑–º—ã

- **FSM-–∏–Ω–≤–∞—Ä–∏–∞–Ω—Ç—ã**: –Ω–µ–ª—å–∑—è –¥–µ–π—Å—Ç–≤–æ–≤–∞—Ç—å –ø—Ä–∏ `ERROR_STATE`
- **BIOS-–∏–Ω–≤–∞—Ä–∏–∞–Ω—Ç—ã**: –ø—Ä–æ–≤–µ—Ä–∫–∞ –∞–ø–ø–∞—Ä–∞—Ç–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
- **–ê–Ω—Ç–∏-—Ñ–ª–∞–ø–ø–∏–Ω–≥**: –∑–∞—â–∏—Ç–∞ –æ—Ç —á–∞—Å—Ç—ã—Ö –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–π –¥–µ–π—Å—Ç–≤–∏–π
- **–ú–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–µ–π—Å—Ç–≤–∏–π**: –º–æ–¥–µ–ª—å –Ω–µ –º–æ–∂–µ—Ç –ø—Ä–µ–¥–ª–æ–∂–∏—Ç—å –∑–∞–ø—Ä–µ—â—ë–Ω–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ
- **–í–∞–ª–∏–¥–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤**: –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–∏–∞–ø–∞–∑–æ–Ω–æ–≤ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–µ–π—Å—Ç–≤–∏–π

### SafetyShield

–ü—Ä–æ–≤–µ—Ä—è–µ—Ç:
- –°–æ—Å—Ç–æ—è–Ω–∏–µ FSM
- –°—Ç–∞—Ç—É—Å BIOS
- –ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–µ–π—Å—Ç–≤–∏–π
- –ß–∞—Å—Ç–æ—Ç—É –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è –¥–µ–π—Å—Ç–≤–∏–π (–∞–Ω—Ç–∏-—Ñ–ª–∞–ø–ø–∏–Ω–≥)

## üìä –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥

### Prometheus-–º–µ—Ç—Ä–∏–∫–∏

| –ú–µ—Ç—Ä–∏–∫–∞ | –û–ø–∏—Å–∞–Ω–∏–µ |
|--------|----------|
| `ne_inference_total` | –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—ã–∑–æ–≤–æ–≤ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ |
| `ne_inference_duration_seconds` | –õ–∞—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ |
| `ne_active_proposals` | –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π |
| `ne_avg_confidence` | –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π |
| `ne_safety_blocks_total` | –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫ SafetyShield |
| `ne_degradation_to_rule` | –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–µ–≥—Ä–∞–¥–∞—Ü–∏–π –≤ RuleEngine |

### Health-check API

```bash
curl http://localhost:5000/health
```

### –¢–µ—Ä–º–∏–Ω–∞–ª—å–Ω—ã–π dashboard

–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ç–µ—Ä–º–∏–Ω–∞–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å —Å —Ä–µ–∞–ª—Ç–∞–π–º –º–µ—Ç—Ä–∏–∫–∞–º–∏ –∏ –ª–æ–≥–∞–º–∏:

```bash
python tools/terminal_dashboard.py
```

–ì–æ—Ä—è—á–∏–µ –∫–ª–∞–≤–∏—à–∏:
- `q` - –í—ã—Ö–æ–¥
- `Ctrl+C` - –ê–≤–∞—Ä–∏–π–Ω—ã–π –≤—ã—Ö–æ–¥

## üì° –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ

### NATS-–ª–æ–≥–≥–µ—Ä

–í—Å–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ª–æ–≥–∏—Ä—É—é—Ç—Å—è –≤ —Ç–æ–ø–∏–∫ `qiki.neural.proposals`

### –¢–µ—Ä–º–∏–Ω–∞–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ

–†–µ–∞–ª—Ç–∞–π–º –≤—ã–≤–æ–¥ –ª–æ–≥–æ–≤ –≤ —Ç–µ—Ä–º–∏–Ω–∞–ª—å–Ω–æ–º dashboard

## üß† –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏

### –°–∫—Ä–∏–ø—Ç –æ–±—É—á–µ–Ω–∏—è

```bash
python train_bc.py
```

–í–∫–ª—é—á–∞–µ—Ç:
- –û–±—É—á–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–º Behavior Cloning
- –≠–∫—Å–ø–æ—Ä—Ç –≤ ONNX
- INT8-–∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è
- –ë–µ–Ω—á–º–∞—Ä–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

### –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞

```bash
python tools/generate_dataset.py
```

–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSONL –¥–ª—è –æ–±—É—á–µ–Ω–∏—è

## üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

### –ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö —Ç–µ—Å—Ç–æ–≤

```bash
python run_tests.py
```

### –ü–æ–∫—Ä—ã—Ç–∏–µ —Ç–µ—Å—Ç–∞–º–∏

| –ö–æ–º–ø–æ–Ω–µ–Ω—Ç | –¢–µ—Å—Ç |
|----------|------|
| `NeuralEngine` | `test_ne_v1_contract.py` |
| `FeatureExtractor` | `test_feature_extractor.py` |
| `SafetyShield` | `test_safety_shield.py` |
| `ProposalEvaluator` | `test_proposal_evaluator.py` |
| `NATSLogger` | `test_nats_logger.py` |
| `DatasetGenerator` | `test_dataset_generator.py` |
| `TerminalDashboard` | `test_terminal_dashboard.py` |

## üê≥ Docker

### Docker Compose

–ó–∞–ø—É—Å–∫ –≤—Å–µ–π —Å–∏—Å—Ç–µ–º—ã:

```bash
docker-compose up -d
```

–í–∫–ª—é—á–∞–µ—Ç:
- QIKI Neural Engine
- Prometheus
- Grafana
- NATS (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

### –û—Ç–¥–µ–ª—å–Ω—ã–π –∑–∞–ø—É—Å–∫

```bash
docker build -t qiki-ne .
docker run qiki-ne
```

## üßæ CI/CD

### GitHub Actions

–§–∞–π–ª: `.github/workflows/ci.yml`

–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∑–∞–ø—É—Å–∫:
- –¢–µ—Å—Ç–æ–≤ –ø—Ä–∏ –∫–∞–∂–¥–æ–º –ø—É—à–µ
- –ü—Ä–æ–≤–µ—Ä–∫–∏ –∫–æ–Ω—Ç—Ä–∞–∫—Ç–æ–≤
- –í–∞–ª–∏–¥–∞—Ü–∏–∏ —Ç–∞–π–º-–±—é–¥–∂–µ—Ç–∞

## üß© –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å QIKI

### –®–∞–≥–∏ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏

1. –†–µ–∞–ª–∏–∑—É–π—Ç–µ `IDataProvider` –¥–ª—è –ø–µ—Ä–µ–¥–∞—á–∏ `AgentContext`
2. –ü–æ–¥–∫–ª—é—á–∏—Ç–µ `NeuralEngineV1` –∫–∞–∫ `INeuralEngine`
3. –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –≤ `configs/config.yaml`
4. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–∏—Å—Ç–µ–º—É —á–µ—Ä–µ–∑ Docker Compose

### –ö–æ–Ω—Ç—Ä–∞–∫—Ç INeuralEngine

```python
class INeuralEngine(ABC):
    def generate_proposals(self, context: Any) -> List[Proposal]:
        pass
```

## üìà –ü–ª–∞–Ω —Ä–∞–∑–≤–∏—Ç–∏—è

### –£—Ä–æ–≤–µ–Ω—å 3 (–¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω–æ)

- Transformer-–º–æ–¥–µ–ª—å –≤–º–µ—Å—Ç–æ GRU
- RL-–æ–±—É—á–µ–Ω–∏–µ (PPO, Offline RL)
- ONNX Server –∫–∞–∫ –æ—Ç–¥–µ–ª—å–Ω—ã–π –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å
- Human-in-the-loop –æ–±—É—á–µ–Ω–∏–µ
- –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∏–Ω—Ñ–µ—Ä–µ–Ω—Å
- Multi-agent –∫–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏—è

## üìÑ –õ–∏—Ü–µ–Ω–∑–∏—è

MIT

## üìû –ö–æ–Ω—Ç–∞–∫—Ç—ã

- –í–µ—Ä—Å–∏—è: 2.0
- –î–∞—Ç–∞: 2025-04-05

---

## üìÅ –§–∞–π–ª—ã –ø—Ä–æ–µ–∫—Ç–∞ (–≤—Å–µ–≥–æ 47 —Ñ–∞–π–ª–æ–≤)

### 1. README.md
```markdown
# üìò QIKI Neural Engine - –ü–æ–ª–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è

## üìã –û–ø–∏—Å–∞–Ω–∏–µ

QIKI Neural Engine - —ç—Ç–æ –∫–æ–º–ø–∞–∫—Ç–Ω—ã–π, –±–µ–∑–æ–ø–∞—Å–Ω—ã–π –∏ CPU-–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤–æ–π –¥–≤–∏–∂–æ–∫ –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –≤ –∞–≥–µ–Ω—Ç–Ω—É—é —Å–∏—Å—Ç–µ–º—É QIKI. –†–µ–∞–ª–∏–∑—É–µ—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏—é "–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π" –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∞–≥–µ–Ω—Ç–∞ –∏ –∏–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç—Å—è –≤ —Ü–∏–∫–ª –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏–π —á–µ—Ä–µ–∑ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å `INeuralEngine`.

## üóÇÔ∏è –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

```
ne_qiki/
‚îú‚îÄ‚îÄ core/                          # –Ø–¥—Ä–æ –¥–≤–∏–∂–∫–∞
‚îÇ   ‚îú‚îÄ‚îÄ interfaces.py              # –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å INeuralEngine
‚îÇ   ‚îú‚îÄ‚îÄ feature_extractor.py       # –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
‚îÇ   ‚îú‚îÄ‚îÄ neural_engine_impl.py      # –†–µ–∞–ª–∏–∑–∞—Ü–∏—è NeuralEngineV1
‚îÇ   ‚îú‚îÄ‚îÄ proposal_evaluator.py      # –û—Ü–µ–Ω–∫–∞ –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
‚îÇ   ‚îú‚îÄ‚îÄ safety.py                  # –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å –∏ –∞–Ω—Ç–∏-—Ñ–ª–∞–ø–ø–∏–Ω–≥
‚îÇ   ‚îú‚îÄ‚îÄ calibration.py             # –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–Ω–∞—è –∫–∞–ª–∏–±—Ä–æ–≤–∫–∞
‚îÇ   ‚îú‚îÄ‚îÄ metrics.py                 # Prometheus-–º–µ—Ç—Ä–∏–∫–∏
‚îÇ   ‚îú‚îÄ‚îÄ nats_logger.py             # NATS-–ª–æ–≥–≥–µ—Ä
‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ models/                        # –ù–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã–µ –º–æ–¥–µ–ª–∏
‚îÇ   ‚îú‚îÄ‚îÄ ne_v1.py                   # GRU+MLP –º–æ–¥–µ–ª—å
‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ shared/                        # –û–±—â–∏–µ –º–æ–¥–µ–ª–∏ –¥–∞–Ω–Ω—ã—Ö
‚îÇ   ‚îú‚îÄ‚îÄ models.py                  # ActuatorCommand, Proposal
‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ configs/                       # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
‚îÇ   ‚îî‚îÄ‚îÄ config.example.yaml        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
‚îú‚îÄ‚îÄ schemas/                       # JSON-—Å—Ö–µ–º—ã
‚îÇ   ‚îú‚îÄ‚îÄ agent_context.schema.json  # –°—Ö–µ–º–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
‚îÇ   ‚îú‚îÄ‚îÄ action_catalog.schema.json # –°—Ö–µ–º–∞ –¥–µ–π—Å—Ç–≤–∏–π
‚îÇ   ‚îî‚îÄ‚îÄ safety.schema.yaml         # –°—Ö–µ–º–∞ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
‚îú‚îÄ‚îÄ api/                           # API
‚îÇ   ‚îî‚îÄ‚îÄ health_check.py            # Health-check API
‚îú‚îÄ‚îÄ benchmark/                     # –ë–µ–Ω—á–º–∞—Ä–∫–∏
‚îÇ   ‚îî‚îÄ‚îÄ onnx_benchmark.py          # –ë–µ–Ω—á–º–∞—Ä–∫ ONNX
‚îú‚îÄ‚îÄ datasets/                      # –†–∞–±–æ—Ç–∞ —Å –¥–∞—Ç–∞—Å–µ—Ç–∞–º–∏
‚îÇ   ‚îî‚îÄ‚îÄ jsonl_dataset.py           # –ó–∞–≥—Ä—É–∑—á–∏–∫ JSONL
‚îú‚îÄ‚îÄ examples/                      # –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
‚îÇ   ‚îî‚îÄ‚îÄ mock_inference.py          # –ü—Ä–∏–º–µ—Ä –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞
‚îú‚îÄ‚îÄ tests/                         # –Æ–Ω–∏—Ç-—Ç–µ—Å—Ç—ã
‚îÇ   ‚îú‚îÄ‚îÄ test_ne_v1_contract.py     # –ö–æ–Ω—Ç—Ä–∞–∫—Ç NeuralEngine
‚îÇ   ‚îú‚îÄ‚îÄ test_feature_extractor.py  # –¢–µ—Å—Ç –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ç–æ—Ä–∞
‚îÇ   ‚îú‚îÄ‚îÄ test_safety_shield.py      # –¢–µ—Å—Ç –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
‚îÇ   ‚îú‚îÄ‚îÄ test_proposal_evaluator.py # –¢–µ—Å—Ç –æ—Ü–µ–Ω—â–∏–∫–∞
‚îÇ   ‚îú‚îÄ‚îÄ test_nats_logger.py        # –¢–µ—Å—Ç NATS-–ª–æ–≥–≥–µ—Ä–∞
‚îÇ   ‚îú‚îÄ‚îÄ test_dataset_generator.py  # –¢–µ—Å—Ç –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞
‚îÇ   ‚îú‚îÄ‚îÄ test_terminal_dashboard.py # –¢–µ—Å—Ç —Ç–µ—Ä–º–∏–Ω–∞–ª—å–Ω–æ–≥–æ dashboard
‚îÇ   ‚îú‚îÄ‚îÄ test_neural_engine_dashboard_integration.py # –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Ç–µ—Å—Ç
‚îÇ   ‚îú‚îÄ‚îÄ test_global_logger.py      # –¢–µ—Å—Ç –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ –ª–æ–≥–≥–µ—Ä–∞
‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ tools/                         # –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã
‚îÇ   ‚îú‚îÄ‚îÄ terminal_dashboard.py      # –¢–µ—Ä–º–∏–Ω–∞–ª—å–Ω—ã–π dashboard
‚îÇ   ‚îú‚îÄ‚îÄ global_logger.py           # –ì–ª–æ–±–∞–ª—å–Ω—ã–π –ª–æ–≥–≥–µ—Ä
‚îÇ   ‚îú‚îÄ‚îÄ generate_dataset.py        # –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞
‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ monitoring/                    # –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
‚îÇ   ‚îú‚îÄ‚îÄ prometheus.yml             # –ö–æ–Ω—Ñ–∏–≥ Prometheus
‚îÇ   ‚îî‚îÄ‚îÄ dashboard.json             # Grafana –¥–∞—à–±–æ—Ä–¥
‚îú‚îÄ‚îÄ train_bc.py                    # –û–±—É—á–µ–Ω–∏–µ –∏ —ç–∫—Å–ø–æ—Ä—Ç ONNX
‚îú‚îÄ‚îÄ run_tests.py                   # –ï–¥–∏–Ω—ã–π —Ç–µ—Å—Ç-—Ä–∞–Ω–Ω–µ—Ä
‚îú‚îÄ‚îÄ Dockerfile                     # Docker-–æ–±—Ä–∞–∑
‚îú‚îÄ‚îÄ docker-compose.yml             # Docker Compose
‚îú‚îÄ‚îÄ requirements.txt               # –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
‚îî‚îÄ‚îÄ .github/
    ‚îî‚îÄ‚îÄ workflows/
        ‚îî‚îÄ‚îÄ ci.yml                 # CI Pipeline
```

## üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

### –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π

```bash
pip install -r requirements.txt
```

### –ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤

```bash
docker-compose up -d
```

### –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

```bash
python examples/mock_inference.py
```

### –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤

```bash
python run_tests.py
```

### –¢–µ—Ä–º–∏–Ω–∞–ª—å–Ω—ã–π dashboard

```bash
python tools/terminal_dashboard.py
```

## üß™ –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

### –û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã

| –ö–æ–º–ø–æ–Ω–µ–Ω—Ç | –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ |
|----------|------------|
| `INeuralEngine` | –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –≤ QIKI |
| `NeuralEngineV1` | –†–µ–∞–ª–∏–∑–∞—Ü–∏—è: –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è ‚Üí –º–æ–¥–µ–ª—å ‚Üí –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è |
| `NE_v1` | GRU(2√ó64) + MLP –≥–æ–ª–æ–≤—ã |
| `FeatureExtractor` | –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç `AgentContext` –≤ —Ç–µ–Ω–∑–æ—Ä |
| `SafetyShield` | –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å –∏ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç —Ñ–ª–∞–ø–ø–∏–Ω–≥ |
| `ProposalEvaluator` | –§–∏–ª—å—Ç—Ä—É–µ—Ç –∏ —Å–æ—Ä—Ç–∏—Ä—É–µ—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è |

### –ü–æ—Ç–æ–∫ –¥–∞–Ω–Ω—ã—Ö

```
AgentContext ‚Üí FeatureExtractor ‚Üí NE_v1 (GRU+MLP) ‚Üí Calibration ‚Üí Proposals ‚Üí 
SafetyShield ‚Üí ProposalEvaluator ‚Üí Decision
```

## üì¶ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

–§–∞–π–ª: `configs/config.example.yaml`

```yaml
window: 16
in_dim: 32
num_classes: 6
param_dim: 4
topk: 3
min_confidence: 0.55
time_budget_ms: 8
calibration:
  temperature: 1.2
action_catalog:
  actions:
    - name: HOLD_POSITION
      params:
        duration: [0.1, 5.0]
    - name: COOLING_BOOST
      params:
        intensity: [0.1, 1.0]
    - name: THROTTLE_DOWN
      params:
        level: [0.0, 1.0]
    - name: THROTTLE_UP
      params:
        level: [0.0, 1.0]
    - name: ROTATE_LEFT
      params:
        angle: [0.0, 3.14]
    - name: ROTATE_RIGHT
      params:
        angle: [0.0, 3.14]
safety:
  fsm_invariants:
    - ERROR_STATE
  bios_invariants:
    - bios_ok
```

## üîê –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å

### –†–µ–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ö–∞–Ω–∏–∑–º—ã

- **FSM-–∏–Ω–≤–∞—Ä–∏–∞–Ω—Ç—ã**: –Ω–µ–ª—å–∑—è –¥–µ–π—Å—Ç–≤–æ–≤–∞—Ç—å –ø—Ä–∏ `ERROR_STATE`
- **BIOS-–∏–Ω–≤–∞—Ä–∏–∞–Ω—Ç—ã**: –ø—Ä–æ–≤–µ—Ä–∫–∞ –∞–ø–ø–∞—Ä–∞—Ç–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
- **–ê–Ω—Ç–∏-—Ñ–ª–∞–ø–ø–∏–Ω–≥**: –∑–∞—â–∏—Ç–∞ –æ—Ç —á–∞—Å—Ç—ã—Ö –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–π –¥–µ–π—Å—Ç–≤–∏–π
- **–ú–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–µ–π—Å—Ç–≤–∏–π**: –º–æ–¥–µ–ª—å –Ω–µ –º–æ–∂–µ—Ç –ø—Ä–µ–¥–ª–æ–∂–∏—Ç—å –∑–∞–ø—Ä–µ—â—ë–Ω–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ
- **–í–∞–ª–∏–¥–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤**: –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–∏–∞–ø–∞–∑–æ–Ω–æ–≤ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–µ–π—Å—Ç–≤–∏–π

### SafetyShield

–ü—Ä–æ–≤–µ—Ä—è–µ—Ç:
- –°–æ—Å—Ç–æ—è–Ω–∏–µ FSM
- –°—Ç–∞—Ç—É—Å BIOS
- –ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–µ–π—Å—Ç–≤–∏–π
- –ß–∞—Å—Ç–æ—Ç—É –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è –¥–µ–π—Å—Ç–≤–∏–π (–∞–Ω—Ç–∏-—Ñ–ª–∞–ø–ø–∏–Ω–≥)

## üìä –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥

### Prometheus-–º–µ—Ç—Ä–∏–∫–∏

| –ú–µ—Ç—Ä–∏–∫–∞ | –û–ø–∏—Å–∞–Ω–∏–µ |
|--------|----------|
| `ne_inference_total` | –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—ã–∑–æ–≤–æ–≤ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ |
| `ne_inference_duration_seconds` | –õ–∞—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ |
| `ne_active_proposals` | –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π |
| `ne_avg_confidence` | –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π |
| `ne_safety_blocks_total` | –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫ SafetyShield |
| `ne_degradation_to_rule` | –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–µ–≥—Ä–∞–¥–∞—Ü–∏–π –≤ RuleEngine |

### Health-check API

```bash
curl http://localhost:5000/health
```

### –¢–µ—Ä–º–∏–Ω–∞–ª—å–Ω—ã–π dashboard

–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ç–µ—Ä–º–∏–Ω–∞–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å —Å —Ä–µ–∞–ª—Ç–∞–π–º –º–µ—Ç—Ä–∏–∫–∞–º–∏ –∏ –ª–æ–≥–∞–º–∏:

```bash
python tools/terminal_dashboard.py
```

–ì–æ—Ä—è—á–∏–µ –∫–ª–∞–≤–∏—à–∏:
- `q` - –í—ã—Ö–æ–¥
- `Ctrl+C` - –ê–≤–∞—Ä–∏–π–Ω—ã–π –≤—ã—Ö–æ–¥

## üì° –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ

### NATS-–ª–æ–≥–≥–µ—Ä

–í—Å–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ª–æ–≥–∏—Ä—É—é—Ç—Å—è –≤ —Ç–æ–ø–∏–∫ `qiki.neural.proposals`

### –¢–µ—Ä–º–∏–Ω–∞–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ

–†–µ–∞–ª—Ç–∞–π–º –≤—ã–≤–æ–¥ –ª–æ–≥–æ–≤ –≤ —Ç–µ—Ä–º–∏–Ω–∞–ª—å–Ω–æ–º dashboard

## üß† –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏

### –°–∫—Ä–∏–ø—Ç –æ–±—É—á–µ–Ω–∏—è

```bash
python train_bc.py
```

–í–∫–ª—é—á–∞–µ—Ç:
- –û–±—É—á–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–º Behavior Cloning
- –≠–∫—Å–ø–æ—Ä—Ç –≤ ONNX
- INT8-–∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è
- –ë–µ–Ω—á–º–∞—Ä–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

### –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞

```bash
python tools/generate_dataset.py
```

–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSONL –¥–ª—è –æ–±—É—á–µ–Ω–∏—è

## üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

### –ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö —Ç–µ—Å—Ç–æ–≤

```bash
python run_tests.py
```

### –ü–æ–∫—Ä—ã—Ç–∏–µ —Ç–µ—Å—Ç–∞–º–∏

| –ö–æ–º–ø–æ–Ω–µ–Ω—Ç | –¢–µ—Å—Ç |
|----------|------|
| `NeuralEngine` | `test_ne_v1_contract.py` |
| `FeatureExtractor` | `test_feature_extractor.py` |
| `SafetyShield` | `test_safety_shield.py` |
| `ProposalEvaluator` | `test_proposal_evaluator.py` |
| `NATSLogger` | `test_nats_logger.py` |
| `DatasetGenerator` | `test_dataset_generator.py` |
| `TerminalDashboard` | `test_terminal_dashboard.py` |

## üê≥ Docker

### Docker Compose

–ó–∞–ø—É—Å–∫ –≤—Å–µ–π —Å–∏—Å—Ç–µ–º—ã:

```bash
docker-compose up -d
```

–í–∫–ª—é—á–∞–µ—Ç:
- QIKI Neural Engine
- Prometheus
- Grafana
- NATS (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

### –û—Ç–¥–µ–ª—å–Ω—ã–π –∑–∞–ø—É—Å–∫

```bash
docker build -t qiki-ne .
docker run qiki-ne
```

## üßæ CI/CD

### GitHub Actions

–§–∞–π–ª: `.github/workflows/ci.yml`

–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∑–∞–ø—É—Å–∫:
- –¢–µ—Å—Ç–æ–≤ –ø—Ä–∏ –∫–∞–∂–¥–æ–º –ø—É—à–µ
- –ü—Ä–æ–≤–µ—Ä–∫–∏ –∫–æ–Ω—Ç—Ä–∞–∫—Ç–æ–≤
- –í–∞–ª–∏–¥–∞—Ü–∏–∏ —Ç–∞–π–º-–±—é–¥–∂–µ—Ç–∞

## üß© –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å QIKI

### –®–∞–≥–∏ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏

1. –†–µ–∞–ª–∏–∑—É–π—Ç–µ `IDataProvider` –¥–ª—è –ø–µ—Ä–µ–¥–∞—á–∏ `AgentContext`
2. –ü–æ–¥–∫–ª—é—á–∏—Ç–µ `NeuralEngineV1` –∫–∞–∫ `INeuralEngine`
3. –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –≤ `configs/config.yaml`
4. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–∏—Å—Ç–µ–º—É —á–µ—Ä–µ–∑ Docker Compose

### –ö–æ–Ω—Ç—Ä–∞–∫—Ç INeuralEngine

```python
class INeuralEngine(ABC):
    def generate_proposals(self, context: Any) -> List[Proposal]:
        pass
```

## üìà –ü–ª–∞–Ω —Ä–∞–∑–≤–∏—Ç–∏—è

### –£—Ä–æ–≤–µ–Ω—å 3 (–¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω–æ)

- Transformer-–º–æ–¥–µ–ª—å –≤–º–µ—Å—Ç–æ GRU
- RL-–æ–±—É—á–µ–Ω–∏–µ (PPO, Offline RL)
- ONNX Server –∫–∞–∫ –æ—Ç–¥–µ–ª—å–Ω—ã–π –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å
- Human-in-the-loop –æ–±—É—á–µ–Ω–∏–µ
- –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∏–Ω—Ñ–µ—Ä–µ–Ω—Å
- Multi-agent –∫–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏—è

## üìÑ –õ–∏—Ü–µ–Ω–∑–∏—è

MIT

## üìû –ö–æ–Ω—Ç–∞–∫—Ç—ã

- –í–µ—Ä—Å–∏—è: 2.0
- –î–∞—Ç–∞: 2025-04-05
```

### 2. requirements.txt
```
torch>=1.13
onnxruntime>=1.14
pyyaml
numpy
flask
prometheus-client
nats-py
prompt_toolkit>=3.0
requests
```

### 3. Dockerfile
```dockerfile
FROM python:3.10-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

CMD ["python", "examples/mock_inference.py"]
```

### 4. docker-compose.yml
```yaml
version: '3.8'

services:
  qiki-ne:
    build: .
    ports:
      - "5000:5000"
    depends_on:
      - prometheus
      - grafana
    environment:
      - FLASK_ENV=production

  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'

  grafana:
    image: grafana/grafana-enterprise
    ports:
      - "3000:3000"
    depends_on:
      - prometheus
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
```

### 5. run_tests.py
```python
import unittest
import sys
import os

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç–∏
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'ne_qiki'))
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'tools'))

def run_all_tests():
    """–ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö —Ç–µ—Å—Ç–æ–≤"""
    loader = unittest.TestLoader()
    suite = unittest.TestSuite()
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ—Å—Ç—ã –∏–∑ —Ä–∞–∑–Ω—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
    suite.addTests(loader.discover('tests', pattern='test_*.py'))
    
    # –°–æ–∑–¥–∞–µ–º runner
    runner = unittest.TextTestRunner(verbosity=2)
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç—ã
    result = runner.run(suite)
    
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–æ–¥ –≤—ã—Ö–æ–¥–∞
    return 0 if result.wasSuccessful() else 1

if __name__ == "__main__":
    exit_code = run_all_tests()
    sys.exit(exit_code)
```

### 6. train_bc.py
```python
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from ne_qiki.models.ne_v1 import NE_v1
import onnx
import onnxruntime as ort
from onnxruntime.quantization import quantize_dynamic, QuantType

# –ü—Ä–∏–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞
class MockDataset(Dataset):
    def __init__(self, size=1000):
        self.size = size

    def __len__(self):
        return self.size

    def __getitem__(self, idx):
        x = torch.randn(16, 32)
        y_class = torch.randint(0, 6, (1,)).long()
        y_priority = torch.rand(1)
        y_params = torch.rand(4)
        mask = torch.ones(6).bool()
        return x, y_class, y_priority, y_params, mask

def train_model():
    model = NE_v1(32, 64, 6, 4)
    dataset = MockDataset(1000)
    loader = DataLoader(dataset, batch_size=8, shuffle=True)
    criterion_cls = nn.CrossEntropyLoss()
    criterion_reg = nn.MSELoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)

    model.train()
    for epoch in range(5):
        for x, y_cls, y_prio, y_param, mask in loader:
            logits, prio, param = model(x, mask)
            loss = criterion_cls(logits, y_cls) + \
                   criterion_reg(prio, y_prio) + \
                   criterion_reg(param, y_param)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
        print(f"Epoch {epoch+1}, Loss: {loss.item():.4f}")

    torch.save(model.state_dict(), "ne_v1.pt")
    print("Model saved as ne_v1.pt")

    # –≠–∫—Å–ø–æ—Ä—Ç –≤ ONNX
    model.eval()
    dummy_input = torch.randn(1, 16, 32)
    dummy_mask = torch.ones(1, 6).bool()
    torch.onnx.export(
        model,
        (dummy_input, dummy_mask),
        "ne_v1.onnx",
        export_params=True,
        opset_version=11,
        do_constant_folding=True,
        input_names=["input", "mask"],
        output_names=["logits", "priority", "params"],
        dynamic_axes={
            "input": {0: "batch", 1: "time"},
            "mask": {0: "batch"},
            "logits": {0: "batch"},
            "priority": {0: "batch"},
            "params": {0: "batch"}
        }
    )
    print("ONNX model exported as ne_v1.onnx")

    # –ö–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è
    quantize_dynamic("ne_v1.onnx", "ne_v1_int8.onnx", weight_type=QuantType.QUInt8)
    print("INT8 quantized model saved as ne_v1_int8.onnx")

if __name__ == "__main__":
    train_model()
```

### 7. ne_qiki/__init__.py
```python
# QIKI Neural Engine package
```

### 8. ne_qiki/core/__init__.py
```python
# Core components package
```

### 9. ne_qiki/core/interfaces.py
```python
from abc import ABC, abstractmethod
from typing import List, Any
from shared.models import Proposal

class INeuralEngine(ABC):
    """
    Abstract interface for the Neural Engine, responsible for generating proposals based on ML models.
    """

    @abstractmethod
    def generate_proposals(self, context: Any) -> List[Proposal]:
        """Generates a list of proposals based on the current agent context using ML models."""
        pass
```

### 10. ne_qiki/core/feature_extractor.py
```python
import torch
import numpy as np
from typing import Tuple

class FeatureExtractor:
    def __init__(self, window: int = 16, in_dim: int = 32):
        self.window = window
        self.in_dim = in_dim

    def extract(self, context) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ AgentContext –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–Ω–∑–æ—Ä –∏ –º–∞—Å–∫—É –¥–µ–π—Å—Ç–≤–∏–π.
        """
        features = []

        # FSM one-hot (–ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º 4 —Å–æ—Å—Ç–æ—è–Ω–∏—è)
        fsm_map = {"BOOTING": 0, "IDLE": 1, "ACTIVE": 2, "ERROR_STATE": 3}
        fsm_vec = np.zeros(4)
        fsm_vec[fsm_map.get(context.fsm_state, 3)] = 1.0
        features.extend(fsm_vec)

        # BIOS —Å—Ç–∞—Ç—É—Å—ã: —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞, –ø–∏—Ç–∞–Ω–∏–µ, utilization
        bios = context.bios_status
        features.extend([
            min(1.0, max(0.0, getattr(bios, 'temperature', 0) / 100.0)),
            min(1.0, max(0.0, getattr(bios, 'power_draw', 0) / 100.0)),
            min(1.0, max(0.0, getattr(bios, 'utilization', 0) / 100.0))
        ])

        # Sensor data
        sensor = context.sensor_data or {}
        features.extend([
            min(1.0, max(0.0, sensor.get("distance", 0.0) / 10.0)),
            min(1.0, max(-1.0, sensor.get("velocity", 0.0) / 5.0)),
            min(1.0, max(-1.0, sensor.get("azimuth", 0.0) / 3.14)),
            min(1.0, max(0.0, sensor.get("hazard_score", 0.0)))
        ])

        # Action history
        hist = sensor.get("action_history", [])
        hist_vec = np.zeros(5)
        for i, act in enumerate(hist[-5:]):
            hist_vec[i] = min(1.0, max(0.0, act / 10.0))
        features.extend(hist_vec)

        # –ü–∞–¥–¥–∏–Ω–≥ –¥–æ in_dim
        while len(features) < self.in_dim:
            features.append(0.0)

        # –¢–µ–Ω–∑–æ—Ä –æ–∫–Ω–∞ (T, in_dim)
        tensor = torch.tensor(features[:self.in_dim], dtype=torch.float32).unsqueeze(0).repeat(self.window, 1).unsqueeze(0)

        # –ü—Ä–∏–º–µ—Ä –º–∞—Å–∫–∏ (–¥–æ–ø—É—Å—Ç–∏–º, –ø–µ—Ä–≤—ã–µ 4 –¥–µ–π—Å—Ç–≤–∏—è —Ä–∞–∑—Ä–µ—à–µ–Ω—ã)
        mask = torch.tensor([True, True, True, True, False, False], dtype=torch.bool).unsqueeze(0)

        return tensor, mask
```

### 11. ne_qiki/core/neural_engine_impl.py
```python
import time
import json
from typing import List
import asyncio
from core.interfaces import INeuralEngine
from shared.models import Proposal, ActuatorCommand
from models.ne_v1 import NE_v1
from core.feature_extractor import FeatureExtractor
from core.calibration import Calibration
from core.safety import SafetyShield
from core.metrics import INFERENCE_COUNT, INFERENCE_LATENCY
from core.nats_logger import NATSLogger
import torch

class NeuralEngineV1(INeuralEngine):
    def __init__(self, config):
        self.model = NE_v1(config['in_dim'], 64, config['num_classes'], config['param_dim'])
        self.extractor = FeatureExtractor(config['window'], config['in_dim'])
        self.calibrator = Calibration(config['calibration']['temperature'])
        self.safety = SafetyShield(config['action_catalog'])
        self.config = config
        self.nats_logger = NATSLogger()
        asyncio.create_task(self.nats_logger.connect())

    def generate_proposals(self, context) -> List[Proposal]:
        start = time.time()
        INFERENCE_COUNT.inc()
        try:
            tensor, mask = self.extractor.extract(context)
            logits, priority, params = self.model(tensor, mask)
            probs = self.calibrator.calibrate(logits)

            proposals = []
            top_k = torch.topk(probs, min(self.config['topk'], probs.size(-1)), dim=-1)
            for i in range(top_k.indices.size(1)):
                idx = top_k.indices[0, i].item()
                conf = top_k.values[0, i].item()
                if conf < self.config['min_confidence']:
                    continue
                action_meta = self.config['action_catalog']['actions'][idx]
                action_name = action_meta['name']
                actuator = ActuatorCommand(action_name, {})
                proposal = Proposal(
                    proposal_id=f"ne_{idx}",
                    source_module_id="NeuralEngineV1",
                    confidence=conf,
                    priority=priority.item(),
                    justification=f"Predicted by NE_v1 for {action_name}",
                    proposed_actions=[actuator]
                )
                proposals.append(proposal)

            # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
            self._log_proposals(proposals, context)

            proposals = self.safety.validate(proposals, context.fsm_state, context.bios_status.ok)
        except Exception as e:
            print(f"[NE] Exception: {e}")
            proposals = []

        elapsed = (time.time() - start) * 1000
        INFERENCE_LATENCY.observe(elapsed / 1000.0)
        if elapsed > self.config['time_budget_ms']:
            print(f"[NE] Timeout: {elapsed:.2f} ms")
            return []
        return proposals

    def _log_proposals(self, proposals, context):
        log_data = {
            "timestamp": time.time(),
            "fsm_state": context.fsm_state,
            "bios_ok": context.bios_status.ok,
            "proposals": [
                {
                    "id": p.proposal_id,
                    "confidence": p.confidence,
                    "priority": p.priority,
                    "action": p.proposed_actions[0].name if p.proposed_actions else None
                }
                for p in proposals
            ]
        }
        print(json.dumps(log_data))
        # NATS logging
        asyncio.create_task(self.nats_logger.log_proposal(log_data))
```

### 12. ne_qiki/core/proposal_evaluator.py
```python
from shared.models import Proposal
from typing import List

class ProposalEvaluator:
    def evaluate(self, proposals: List[Proposal]) -> List[Proposal]:
        # –§–∏–ª—å—Ç—Ä –ø–æ confidence
        filtered = [p for p in proposals if p.confidence >= 0.5]
        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ priority + confidence
        filtered.sort(key=lambda x: (x.priority, x.confidence), reverse=True)
        return filtered[:3]
```

### 13. ne_qiki/core/safety.py
```python
from shared.models import Proposal, ActuatorCommand
from collections import deque

class SafetyShield:
    def __init__(self, action_catalog, max_actions_per_tick=3, flap_window=5):
        self.action_catalog = {a['name']: a for a in action_catalog['actions']}
        self.max_actions = max_actions_per_tick
        self.flap_window = flap_window
        self.action_history = deque(maxlen=flap_window)

    def validate(self, proposals: list, fsm_state: str, bios_ok: bool) -> list:
        if fsm_state == "ERROR_STATE" or not bios_ok:
            return []

        filtered = []
        for p in proposals:
            if len(p.proposed_actions) > self.max_actions:
                continue
            valid = True
            for cmd in p.proposed_actions:
                if not self._validate_action(cmd):
                    valid = False
                    break
            if valid and not self._is_flapping(p):
                filtered.append(p)
                self.action_history.append(p.proposed_actions[0].name if p.proposed_actions else None)
        return filtered

    def _validate_action(self, cmd: ActuatorCommand) -> bool:
        meta = self.action_catalog.get(cmd.name)
        if not meta:
            return False
        for k, v in cmd.params.items():
            vmin, vmax = meta['params'].get(k, (None, None))
            if vmin is not None and not (vmin <= v <= vmax):
                return False
        return True

    def _is_flapping(self, proposal):
        if not self.action_history:
            return False
        last_action = self.action_history[-1]
        current_action = proposal.proposed_actions[0].name if proposal.proposed_actions else None
        return last_action == current_action and len([a for a in self.action_history if a == current_action]) >= 2
```

### 14. ne_qiki/core/calibration.py
```python
import torch

class Calibration:
    def __init__(self, temperature: float = 1.0):
        self.temperature = temperature

    def calibrate(self, logits: torch.Tensor) -> torch.Tensor:
        return torch.softmax(logits / self.temperature, dim=-1)
```

### 15. ne_qiki/core/metrics.py
```python
from prometheus_client import Counter, Histogram, Gauge

INFERENCE_COUNT = Counter('ne_inference_total', 'Total inference calls')
INFERENCE_LATENCY = Histogram('ne_inference_duration_seconds', 'Inference latency')
ACTIVE_PROPOSALS = Gauge('ne_active_proposals', 'Number of active proposals generated')
AVG_CONFIDENCE = Gauge('ne_avg_confidence', 'Average confidence of proposals')
SAFETY_BLOCKS = Counter('ne_safety_blocks_total', 'Total safety blocks')
DEGRADATIONS = Counter('ne_degradation_to_rule', 'Total degradations to rule engine')
```

### 16. ne_qiki/core/nats_logger.py
```python
import json
import asyncio
import nats

class NATSLogger:
    def __init__(self, nats_url="nats://localhost:4222"):
        self.nats_url = nats_url
        self.nc = None

    async def connect(self):
        try:
            self.nc = await nats.connect(self.nats_url)
        except Exception as e:
            print(f"[NATS] Connection failed: {e}")

    async def log_proposal(self, proposal_data):
        if self.nc:
            try:
                await self.nc.publish("qiki.neural.proposals", json.dumps(proposal_data).encode())
            except Exception as e:
                print(f"[NATS] Publish failed: {e}")

    async def close(self):
        if self.nc:
            await self.nc.close()
```

### 17. ne_qiki/models/__init__.py
```python
# Models package
```

### 18. ne_qiki/models/ne_v1.py
```python
import torch
import torch.nn as nn

class NE_v1(nn.Module):
    def __init__(self, input_dim: int, hidden_dim: int, num_classes: int, param_dim: int):
        super().__init__()
        self.gru = nn.GRU(input_dim, hidden_dim, batch_first=True, num_layers=2)
        self.class_head = nn.Linear(hidden_dim, num_classes)
        self.priority_head = nn.Sequential(
            nn.Linear(hidden_dim, 1),
            nn.Sigmoid()
        )
        self.param_head = nn.Linear(hidden_dim, param_dim)

    def forward(self, x, action_mask=None):
        out, _ = self.gru(x)
        features = out[:, -1, :]  # –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ç–∞–π–º—Å—Ç–µ–ø

        logits = self.class_head(features)
        if action_mask is not None:
            logits = logits.masked_fill(~action_mask.bool(), float('-inf'))

        priority = self.priority_head(features).squeeze(-1)
        params = self.param_head(features)

        return logits, priority, params
```

### 19. ne_qiki/shared/__init__.py
```python
# Shared models package
```

### 20. ne_qiki/shared/models.py
```python
from dataclasses import dataclass
from typing import Dict, List, Optional

@dataclass
class ActuatorCommand:
    name: str
    params: Dict[str, float]

@dataclass
class Proposal:
    proposal_id: str
    source_module_id: str
    confidence: float
    priority: float
    justification: str
    proposed_actions: List[ActuatorCommand]
```

### 21. ne_qiki/configs/config.example.yaml
```yaml
window: 16
in_dim: 32
num_classes: 6
param_dim: 4
topk: 3
min_confidence: 0.55
time_budget_ms: 8
calibration:
  temperature: 1.2
action_catalog:
  actions:
    - name: HOLD_POSITION
      params:
        duration: [0.1, 5.0]
    - name: COOLING_BOOST
      params:
        intensity: [0.1, 1.0]
    - name: THROTTLE_DOWN
      params:
        level: [0.0, 1.0]
    - name: THROTTLE_UP
      params:
        level: [0.0, 1.0]
    - name: ROTATE_LEFT
      params:
        angle: [0.0, 3.14]
    - name: ROTATE_RIGHT
      params:
        angle: [0.0, 3.14]
safety:
  fsm_invariants:
    - ERROR_STATE
  bios_invariants:
    - bios_ok
```

### 22. ne_qiki/schemas/agent_context.schema.json
```json
{
  "type": "object",
  "properties": {
    "bios_status": {
      "type": "object",
      "properties": {
        "ok": {"type": "boolean"}
      },
      "required": ["ok"]
    },
    "fsm_state": {
      "type": "string"
    },
    "sensor_data": {
      "type": "object"
    }
  },
  "required": ["bios_status", "fsm_state"]
}
```

### 23. ne_qiki/schemas/action_catalog.schema.json
```json
{
  "type": "object",
  "properties": {
    "actions": {
      "type": "array",
      "items": {
        "type": "object",
        "properties": {
          "name": {"type": "string"},
          "params": {
            "type": "object",
            "additionalProperties": {
              "type": "array",
              "items": {"type": "number"},
              "minItems": 2,
              "maxItems": 2
            }
          }
        },
        "required": ["name", "params"]
      }
    }
  }
}
```

### 24. ne_qiki/schemas/safety.schema.yaml
```yaml
fsm_invariants:
  - ERROR_STATE
bios_invariants:
  - bios_ok
max_actions_per_tick: 3
```

### 25. ne_qiki/api/__init__.py
```python
# API package
```

### 26. ne_qiki/api/health_check.py
```python
from flask import Flask, jsonify
import torch

app = Flask(__name__)

@app.route("/health", methods=["GET"])
def health():
    try:
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏
        x = torch.randn(1, 16, 32)
        mask = torch.ones(1, 6).bool()
        return jsonify({"status": "ok", "model": "loaded"}), 200
    except Exception as e:
        return jsonify({"status": "error", "details": str(e)}), 500

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000)
```

### 27. ne_qiki/benchmark/__init__.py
```python
# Benchmark package
```

### 28. ne_qiki/benchmark/onnx_benchmark.py
```python
import time
import torch
import onnxruntime as ort

def benchmark_onnx(model_path: str, iterations: int = 100):
    session = ort.InferenceSession(model_path)
    dummy_input = torch.randn(1, 16, 32).numpy()
    dummy_mask = torch.ones(1, 6).bool().numpy()

    # Warmup
    for _ in range(10):
        session.run(None, {"input": dummy_input, "mask": dummy_mask})

    # Benchmark
    start = time.time()
    for _ in range(iterations):
        session.run(None, {"input": dummy_input, "mask": dummy_mask})
    elapsed = time.time() - start

    avg_ms = (elapsed / iterations) * 1000
    print(f"ONNX Inference Avg Latency: {avg_ms:.2f} ms")
    return avg_ms

if __name__ == "__main__":
    benchmark_onnx("ne_v1_int8.onnx")
```

### 29. ne_qiki/datasets/__init__.py
```python
# Datasets package
```

### 30. ne_qiki/datasets/jsonl_dataset.py
```python
import json
import torch
from torch.utils.data import Dataset

class JSONLDataset(Dataset):
    def __init__(self, path: str):
        self.data = []
        with open(path, 'r') as f:
            for line in f:
                self.data.append(json.loads(line))

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        item = self.data[idx]
        features = torch.tensor(item['features'], dtype=torch.float32)
        label = torch.tensor(item['label'], dtype=torch.long)
        priority = torch.tensor(item['priority'], dtype=torch.float32)
        params = torch.tensor(item['params'], dtype=torch.float32)
        mask = torch.tensor(item['action_mask'], dtype=torch.bool)
        return features, label, priority, params, mask
```

### 31. ne_qiki/examples/__init__.py
```python
# Examples package
```

### 32. ne_qiki/examples/mock_inference.py
```python
from core.neural_engine_impl import NeuralEngineV1
from dataclasses import dataclass

@dataclass
class MockBiosStatus:
    ok: bool

@dataclass
class MockContext:
    bios_status: MockBiosStatus
    fsm_state: str

if __name__ == "__main__":
    config = {
        "window": 16,
        "in_dim": 32,
        "num_classes": 6,
        "param_dim": 4,
        "topk": 3,
        "min_confidence": 0.55,
        "time_budget_ms": 8,
        "calibration": {"temperature": 1.2},
        "action_catalog": {
            "actions": [
                {"name": "HOLD_POSITION", "params": {}},
                {"name": "COOLING_BOOST", "params": {}},
            ]
        }
    }

    engine = NeuralEngineV1(config)
    context = MockContext(bios_status=MockBiosStatus(ok=True), fsm_state="ACTIVE")
    proposals = engine.generate_proposals(context)
    for p in proposals:
        print(p)
```

### 33. tests/__init__.py
```python
# Tests package
```

### 34. tests/test_ne_v1_contract.py
```python
import unittest
from core.neural_engine_impl import NeuralEngineV1
from shared.models import Proposal
from dataclasses import dataclass
from typing import Dict, List

@dataclass
class MockBiosStatus:
    ok: bool = True
    temperature: float = 50.0
    power_draw: float = 50.0
    utilization: float = 50.0

@dataclass
class MockContext:
    bios_status: MockBiosStatus
    fsm_state: str
    sensor_data: Dict = None

class TestNeuralEngineV1(unittest.TestCase):
    def setUp(self):
        self.config = {
            "window": 16,
            "in_dim": 32,
            "num_classes": 6,
            "param_dim": 4,
            "topk": 3,
            "min_confidence": 0.55,
            "time_budget_ms": 8,
            "calibration": {"temperature": 1.2},
            "action_catalog": {
                "actions": [
                    {"name": "HOLD_POSITION", "params": {}},
                    {"name": "COOLING_BOOST", "params": {}},
                ]
            }
        }
        self.engine = NeuralEngineV1(self.config)

    def test_generate_proposals(self):
        context = MockContext(bios_status=MockBiosStatus(ok=True), fsm_state="ACTIVE")
        proposals = self.engine.generate_proposals(context)
        self.assertIsInstance(proposals, list)
        if proposals:
            self.assertIsInstance(proposals[0], Proposal)

    def test_error_state_returns_empty(self):
        context = MockContext(bios_status=MockBiosStatus(ok=True), fsm_state="ERROR_STATE")
        proposals = self.engine.generate_proposals(context)
        self.assertEqual(proposals, [])

if __name__ == "__main__":
    unittest.main()
```

### 35. tests/test_feature_extractor.py
```python
import unittest
import torch
from core.feature_extractor import FeatureExtractor
from dataclasses import dataclass

@dataclass
class MockBiosStatus:
    temperature: float = 50.0
    power_draw: float = 50.0
    utilization: float = 50.0
    ok: bool = True

@dataclass
class MockContext:
    bios_status: MockBiosStatus
    fsm_state: str
    sensor_data: dict = None

class TestFeatureExtractor(unittest.TestCase):
    def setUp(self):
        self.extractor = FeatureExtractor(window=16, in_dim=32)

    def test_extract_shape(self):
        context = MockContext(
            bios_status=MockBiosStatus(),
            fsm_state="ACTIVE",
            sensor_data={"distance": 5.0, "velocity": 1.0, "azimuth": 0.5, "hazard_score": 0.3}
        )
        tensor, mask = self.extractor.extract(context)
        self.assertEqual(tensor.shape, (1, 16, 32))
        self.assertEqual(mask.shape, (1, 6))

if __name__ == "__main__":
    unittest.main()
```

### 36. tests/test_safety_shield.py
```python
import unittest
from core.safety import SafetyShield
from shared.models import Proposal, ActuatorCommand

class TestSafetyShield(unittest.TestCase):
    def setUp(self):
        self.catalog = {
            "actions": [
                {"name": "HOLD_POSITION", "params": {}},
                {"name": "THROTTLE_UP", "params": {"level": [0.0, 1.0]}}
            ]
        }
        self.shield = SafetyShield(self.catalog)

    def test_validate_ok(self):
        proposal = Proposal(
            proposal_id="test",
            source_module_id="test",
            confidence=0.9,
            priority=0.8,
            justification="test",
            proposed_actions=[ActuatorCommand("HOLD_POSITION", {})]
        )
        result = self.shield.validate([proposal], "ACTIVE", True)
        self.assertEqual(len(result), 1)

    def test_validate_error_state(self):
        proposal = Proposal(
            proposal_id="test",
            source_module_id="test",
            confidence=0.9,
            priority=0.8,
            justification="test",
            proposed_actions=[ActuatorCommand("HOLD_POSITION", {})]
        )
        result = self.shield.validate([proposal], "ERROR_STATE", True)
        self.assertEqual(len(result), 0)

if __name__ == "__main__":
    unittest.main()
```

### 37. tests/test_proposal_evaluator.py
```python
import unittest
from core.proposal_evaluator import ProposalEvaluator
from shared.models import Proposal, ActuatorCommand

class TestProposalEvaluator(unittest.TestCase):
    def setUp(self):
        self.evaluator = ProposalEvaluator()

    def test_evaluate(self):
        proposals = [
            Proposal("1", "test", 0.6, 0.9, "test", [ActuatorCommand("HOLD", {})]),
            Proposal("2", "test", 0.4, 0.8, "test", [ActuatorCommand("MOVE", {})]),
            Proposal("3", "test", 0.7, 0.7, "test", [ActuatorCommand("STOP", {})])
        ]
        result = self.evaluator.evaluate(proposals)
        self.assertEqual(len(result), 2)
        self.assertEqual(result[0].proposal_id, "1")

if __name__ == "__main__":
    unittest.main()
```

### 38. tests/test_nats_logger.py
```python
import unittest
from unittest.mock import AsyncMock, patch
import asyncio
from core.nats_logger import NATSLogger

class TestNATSLogger(unittest.TestCase):
    def setUp(self):
        self.logger = NATSLogger()

    @patch('core.nats_logger.nats.connect')
    def test_connect(self, mock_connect):
        mock_connect.return_value = AsyncMock()
        async def run_test():
            await self.logger.connect()
            mock_connect.assert_called_once()
        
        asyncio.run(run_test())

    @patch('core.nats_logger.nats.connect')
    def test_log_proposal(self, mock_connect):
        mock_nc = AsyncMock()
        mock_connect.return_value = mock_nc
        
        async def run_test():
            await self.logger.connect()
            await self.logger.log_proposal({"test": "data"})
            mock_nc.publish.assert_called_once()
        
        asyncio.run(run_test())

if __name__ == "__main__":
    unittest.main()
```

### 39. tests/test_dataset_generator.py
```python
import unittest
import os
from tools.generate_dataset import generate_dataset

class TestDatasetGenerator(unittest.TestCase):
    def test_generate_dataset(self):
        path = "test_dataset.jsonl"
        generate_dataset(path, size=10)
        self.assertTrue(os.path.exists(path))
        
        # –ü—Ä–æ–≤–µ—Ä–∏–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
        with open(path, 'r') as f:
            lines = f.readlines()
            self.assertEqual(len(lines), 10)
        
        # –£–¥–∞–ª–∏–º —Ç–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª
        os.remove(path)

if __name__ == "__main__":
    unittest.main()
```

### 40. tests/test_terminal_dashboard.py
```python
import unittest
from unittest.mock import patch, MagicMock
import sys
import os
import json

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ tools
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'tools'))

class TestTerminalDashboard(unittest.TestCase):
    def setUp(self):
        # –ú–æ–∫–∞–µ–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ prompt_toolkit
        self.mock_application = MagicMock()
        self.mock_layout = MagicMock()
        self.mock_bindings = MagicMock()
        
        # –ú–æ–∫–∞–µ–º requests
        self.mock_requests = MagicMock()
        
    @patch('tools.terminal_dashboard.requests')
    def test_query_prometheus_success(self, mock_requests):
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –º–æ–∫–∞
        mock_response = MagicMock()
        mock_response.status_code = 200
        mock_response.json.return_value = {
            'status': 'success',
            'data': {
                'result': [{'value': [None, '125.5']}]
            }
        }
        mock_requests.get.return_value = mock_response
        
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ—Å–ª–µ –º–æ–∫–∞
        from tools.terminal_dashboard import TerminalDashboard
        dashboard = TerminalDashboard()
        
        # –¢–µ—Å—Ç
        result = dashboard.query_prometheus('test_query')
        self.assertEqual(result, 125.5)
        
    @patch('tools.terminal_dashboard.requests')
    def test_query_prometheus_failure(self, mock_requests):
        # –ú–æ–∫–∞–µ–º –æ—à–∏–±–∫—É
        mock_requests.get.side_effect = Exception("Connection failed")
        
        from tools.terminal_dashboard import TerminalDashboard
        dashboard = TerminalDashboard()
        
        # –¢–µ—Å—Ç
        result = dashboard.query_prometheus('test_query')
        self.assertEqual(result, 0.0)
        
    def test_add_log(self):
        from tools.terminal_dashboard import TerminalDashboard
        dashboard = TerminalDashboard()
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ª–æ–≥–∏
        dashboard.add_log("Test log 1")
        dashboard.add_log("Test log 2")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º
        self.assertIn("Test log 1", dashboard.logs_text.text)
        self.assertIn("Test log 2", dashboard.logs_text.text)
        
    def test_log_limit(self):
        from tools.terminal_dashboard import TerminalDashboard
        dashboard = TerminalDashboard()
        
        # –î–æ–±–∞–≤–ª—è–µ–º –±–æ–ª—å—à–µ 50 –ª–æ–≥–æ–≤
        for i in range(60):
            dashboard.add_log(f"Log {i}")
            
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –æ—Å—Ç–∞–ª–æ—Å—å —Ç–æ–ª—å–∫–æ 50
        lines = dashboard.logs_text.text.strip().split('\n')
        self.assertEqual(len(lines), 50)
        self.assertIn("Log 59", dashboard.logs_text.text)  # –ü–æ—Å–ª–µ–¥–Ω–∏–π
        self.assertNotIn("Log 0", dashboard.logs_text.text)  # –ü–µ—Ä–≤—ã–π —É–¥–∞–ª—ë–Ω
        
    @patch('tools.terminal_dashboard.threading')
    def test_auto_refresh_starts_thread(self, mock_threading):
        from tools.terminal_dashboard import TerminalDashboard
        dashboard = TerminalDashboard()
        
        # –ú–æ–∫–∞–µ–º –º–µ—Ç–æ–¥ update_metrics
        dashboard.update_metrics = MagicMock()
        
        # –í—ã–∑—ã–≤–∞–µ–º auto_refresh
        dashboard.auto_refresh()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ thread –±—ã–ª —Å–æ–∑–¥–∞–Ω
        mock_threading.Thread.assert_called()
        
    def test_metrics_text_format(self):
        from tools.terminal_dashboard import TerminalDashboard
        dashboard = TerminalDashboard()
        
        # –ú–æ–∫–∞–µ–º query_prometheus
        dashboard.query_prometheus = MagicMock(return_value=125.5)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
        dashboard.update_metrics()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–æ—Ä–º–∞—Ç
        text = dashboard.metrics_text.text
        self.assertIn("Inference Rate", text)
        self.assertIn("125.50", text)
        self.assertIn("QIKI Neural Engine Metrics", text)

if __name__ == '__main__':
    unittest.main()
```

### 41. tests/test_neural_engine_dashboard_integration.py
```python
import unittest
import sys
import os
from unittest.mock import patch, MagicMock

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç–∏
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'ne_qiki'))
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'tools'))

class TestNeuralEngineDashboardIntegration(unittest.TestCase):
    def setUp(self):
        # –ú–æ–∫–∞–µ–º torch –∏ –º–æ–¥–µ–ª—å
        self.mock_torch = MagicMock()
        self.mock_model = MagicMock()
        
    @patch('ne_qiki.core.neural_engine_impl.torch')
    @patch('ne_qiki.core.neural_engine_impl.NE_v1')
    def test_neural_engine_logs_to_dashboard(self, mock_ne_v1, mock_torch):
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –º–æ–∫–æ–≤
        mock_ne_v1.return_value = self.mock_model
        mock_torch.tensor.return_value = MagicMock()
        mock_torch.ones.return_value = MagicMock()
        
        # –ú–æ–∫–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –º–æ–¥–µ–ª–∏
        mock_logits = MagicMock()
        mock_logits.size.return_value = [1, 6]
        self.mock_model.return_value = (mock_logits, MagicMock(), MagicMock())
        
        # –ú–æ–∫–∞–µ–º topk
        mock_topk_result = MagicMock()
        mock_topk_result.indices = MagicMock()
        mock_topk_result.indices.size.return_value = [1, 3]
        mock_topk_result.indices.__getitem__.return_value = MagicMock()
        mock_topk_result.indices.__getitem__.return_value.item.return_value = 0
        mock_topk_result.values = MagicMock()
        mock_topk_result.values.__getitem__.return_value = MagicMock()
        mock_topk_result.values.__getitem__.return_value.item.return_value = 0.8
        
        mock_torch.topk.return_value = mock_topk_result
        
        # –ú–æ–∫–∞–µ–º softmax
        mock_torch.softmax.return_value = mock_topk_result.values
        
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ—Å–ª–µ –º–æ–∫–∞
        from ne_qiki.core.neural_engine_impl import NeuralEngineV1
        from ne_qiki.shared.models import Proposal, ActuatorCommand
        from dataclasses import dataclass
        
        @dataclass
        class MockBiosStatus:
            ok: bool = True
            temperature: float = 50.0
            power_draw: float = 50.0
            utilization: float = 50.0
        
        @dataclass
        class MockContext:
            bios_status: MockBiosStatus
            fsm_state: str = "ACTIVE"
            sensor_data: dict = None
        
        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
        config = {
            "window": 16,
            "in_dim": 32,
            "num_classes": 6,
            "param_dim": 4,
            "topk": 3,
            "min_confidence": 0.55,
            "time_budget_ms": 8,
            "calibration": {"temperature": 1.2},
            "action_catalog": {
                "actions": [
                    {"name": "HOLD_POSITION", "params": {}},
                ]
            }
        }
        
        # –°–æ–∑–¥–∞–µ–º engine
        engine = NeuralEngineV1(config)
        
        # –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
        context = MockContext(bios_status=MockBiosStatus())
        
        # –ú–æ–∫–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π –ª–æ–≥–≥–µ—Ä
        with patch('ne_qiki.core.neural_engine_impl.GLOBAL_LOGGER') as mock_logger:
            # –í—ã–∑—ã–≤–∞–µ–º generate_proposals
            proposals = engine.generate_proposals(context)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ª–æ–≥–≥–µ—Ä –±—ã–ª –≤—ã–∑–≤–∞–Ω
            mock_logger.add_log.assert_called()

if __name__ == '__main__':
    unittest.main()
```

### 42. tests/test_global_logger.py
```python
import unittest
import sys
import os

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ tools
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'tools'))

class TestGlobalLogger(unittest.TestCase):
    def test_global_logger_singleton(self):
        from tools.global_logger import GLOBAL_LOGGER
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ —Å–∏–Ω–≥–ª—Ç–æ–Ω
        from tools.global_logger import GlobalLogger
        logger2 = GlobalLogger()
        
        # GLOBAL_LOGGER –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ–¥–Ω–∏–º –∏ —Ç–µ–º –∂–µ —ç–∫–∑–µ–º–ø–ª—è—Ä–æ–º
        self.assertIsNotNone(GLOBAL_LOGGER)
        
    def test_set_dashboard(self):
        from tools.global_logger import GLOBAL_LOGGER
        
        # –°–æ–∑–¥–∞–µ–º –º–æ–∫ dashboard
        mock_dashboard = unittest.mock.MagicMock()
        
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º dashboard
        GLOBAL_LOGGER.set_dashboard(mock_dashboard)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ dashboard —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω
        self.assertEqual(GLOBAL_LOGGER.dashboard, mock_dashboard)
        
    def test_add_log_without_dashboard(self):
        from tools.global_logger import GLOBAL_LOGGER
        
        # –°–±—Ä–∞—Å—ã–≤–∞–µ–º dashboard
        GLOBAL_LOGGER.dashboard = None
        
        # –î–æ–ª–∂–Ω–æ —Ä–∞–±–æ—Ç–∞—Ç—å –±–µ–∑ –æ—à–∏–±–æ–∫
        try:
            GLOBAL_LOGGER.add_log("Test message")
            success = True
        except:
            success = False
            
        self.assertTrue(success)
        
    def test_add_log_with_dashboard(self):
        from tools.global_logger import GLOBAL_LOGGER
        
        # –°–æ–∑–¥–∞–µ–º –º–æ–∫ dashboard
        mock_dashboard = unittest.mock.MagicMock()
        GLOBAL_LOGGER.set_dashboard(mock_dashboard)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ª–æ–≥
        GLOBAL_LOGGER.add_log("Test message")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –º–µ—Ç–æ–¥ dashboard.add_log –±—ã–ª –≤—ã–∑–≤–∞–Ω
        mock_dashboard.add_log.assert_called_once_with("Test message")

if __name__ == '__main__':
    unittest.main()
```

### 43. tools/__init__.py
```python
# Tools package
```

### 44. tools/terminal_dashboard.py
```python
import asyncio
import requests
import json
from datetime import datetime
from prompt_toolkit import Application
from prompt_toolkit.layout import Layout, HSplit, VSplit
from prompt_toolkit.widgets import Frame, TextArea, Label
from prompt_toolkit.layout.containers import Window
from prompt_toolkit.layout.controls import FormattedTextControl
from prompt_toolkit.key_binding import KeyBindings
import threading
import time

class TerminalDashboard:
    def __init__(self, prometheus_url="http://localhost:9090"):
        self.prometheus_url = prometheus_url
        self.running = True
        
        # UI Components
        self.title_label = Label("QIKI Neural Engine - Terminal Dashboard")
        self.status_label = Label("Status: Running")
        self.metrics_text = TextArea(text="Loading metrics...", height=10)
        self.logs_text = TextArea(text="Waiting for logs...", height=10)
        self.footer_label = Label("Press 'q' to quit | Auto-refresh: 2s")
        
        # Layout
        self.root_container = HSplit([
            Frame(self.title_label, style="class:title"),
            Frame(self.status_label, style="class:status"),
            Frame(Label("Metrics"), body=self.metrics_text),
            Frame(Label("Recent Logs"), body=self.logs_text),
            Frame(self.footer_label, style="class:footer")
        ])
        
        self.layout = Layout(self.root_container)
        
        # Key bindings
        self.bindings = KeyBindings()
        
        @self.bindings.add('q')
        def _(event):
            self.running = False
            event.app.exit()
            
        @self.bindings.add('c-c')
        def _(event):
            self.running = False
            event.app.exit()
        
        # App
        self.app = Application(
            layout=self.layout,
            key_bindings=self.bindings,
            full_screen=True
        )
        
        # Data storage
        self.logs = []
        
    def query_prometheus(self, query):
        """Query Prometheus API"""
        try:
            url = f"{self.prometheus_url}/api/v1/query"
            response = requests.get(url, params={'query': query}, timeout=2)
            if response.status_code == 200:
                data = response.json()
                if data['status'] == 'success' and data['data']['result']:
                    return float(data['data']['result'][0]['value'][1])
            return 0.0
        except:
            return 0.0
    
    def update_metrics(self):
        """Update metrics display"""
        try:
            # Get metrics
            inference_rate = self.query_prometheus('rate(ne_inference_total[1m])')
            latency = self.query_prometheus('histogram_quantile(0.95, rate(ne_inference_duration_seconds_bucket[1m]))')
            avg_confidence = self.query_prometheus('avg(ne_avg_confidence)')
            
            # Format metrics text
            metrics_text = f"""QIKI Neural Engine Metrics
====================================================================================================
Inference Rate:     {inference_rate:.2f} infers/sec
95th Latency:       {latency*1000:.2f} ms
Avg Confidence:     {avg_confidence:.3f}
Safety Blocks:      {self.query_prometheus('ne_safety_blocks_total')}
Degradations:       {self.query_prometheus('ne_degradation_to_rule')}
====================================================================================================
"""
            self.metrics_text.text = metrics_text
            
        except Exception as e:
            self.metrics_text.text = f"Error fetching metrics: {str(e)}"
    
    def add_log(self, log_entry):
        """Add log entry to display"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        self.logs.append(f"[{timestamp}] {log_entry}")
        # Keep only last 50 logs
        self.logs = self.logs[-50:]
        self.logs_text.text = "\n".join(self.logs)
    
    def auto_refresh(self):
        """Auto-refresh metrics"""
        while self.running:
            try:
                self.update_metrics()
                time.sleep(2)
            except:
                pass
    
    def run(self):
        """Run the dashboard"""
        # Start auto-refresh thread
        refresh_thread = threading.Thread(target=self.auto_refresh, daemon=True)
        refresh_thread.start()
        
        # Run application
        self.app.run()
        
        self.running = False

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    dashboard = TerminalDashboard()
    
    # –î–æ–±–∞–≤–∏–º —Ç–µ—Å—Ç–æ–≤—ã–µ –ª–æ–≥–∏
    def simulate_logs():
        import time
        import random
        logs = [
            "NeuralEngine: Proposal generated (HOLD_POSITION, conf=0.87)",
            "SafetyShield: Action validated OK",
            "ProposalEvaluator: Selected priority=0.92",
            "FSM: State changed to ACTIVE",
            "BIOS: All systems OK",
            "Timeout: 6.2ms (within budget)",
            "Warning: Low confidence (0.45) - degrading to RuleEngine"
        ]
        while dashboard.running:
            if random.random() < 0.3:  # 30% chance per 0.5s
                log = random.choice(logs)
                dashboard.add_log(log)
            time.sleep(0.5)
    
    # Start log simulation
    log_thread = threading.Thread(target=simulate_logs, daemon=True)
    log_thread.start()
    
    # Run dashboard
    dashboard.run()
```

### 45. tools/global_logger.py
```python
class GlobalLogger:
    def __init__(self):
        self.dashboard = None
    
    def set_dashboard(self, dashboard):
        self.dashboard = dashboard
    
    def add_log(self, message):
        if self.dashboard:
            self.dashboard.add_log(message)

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä
GLOBAL_LOGGER = GlobalLogger()
```

### 46. tools/generate_dataset.py
```python
import json
import random
import numpy as np

def generate_sample():
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ–¥–∏–Ω –ø—Ä–∏–º–µ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏ –¥–µ–π—Å—Ç–≤–∏—è"""
    fsm_states = ["BOOTING", "IDLE", "ACTIVE", "ERROR_STATE"]
    actions = list(range(6))
    
    # –ö–æ–Ω—Ç–µ–∫—Å—Ç
    features = np.random.randn(32).tolist()
    
    # –ú–µ—Ç–∫–∏
    label = random.choice(actions)
    priority = random.random()
    params = np.random.randn(4).tolist()
    mask = [True, True, True, True, False, False]
    
    return {
        "features": features,
        "label": label,
        "priority": priority,
        "params": params,
        "action_mask": mask
    }

def generate_dataset(path="dataset.jsonl", size=1000):
    with open(path, 'w') as f:
        for _ in range(size):
            sample = generate_sample()
            f.write(json.dumps(sample) + '\n')
    print(f"Dataset saved to {path}")

if __name__ == "__main__":
    generate_dataset()
```

### 47. monitoring/prometheus.yml
```yaml
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'qiki-ne'
    static_configs:
      - targets: ['qiki-ne:5000']
```

### USER
–£–î–û–°–¢–û–í–ï–†–¨–°–Ø –ß–¢–û –í–°–ï –•–û–†–û–®–û


### ASSISTANT
## ‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–ª–Ω–æ—Ç—ã –ø—Ä–æ–µ–∫—Ç–∞

### üìä –°—Ç–∞—Ç—É—Å: –í–°–ï –§–ê–ô–õ–´ –ü–†–ï–î–û–°–¢–ê–í–õ–ï–ù–´

–Ø –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏–ª –≤—Å–µ 47 —Ñ–∞–π–ª–æ–≤ –ø—Ä–æ–µ–∫—Ç–∞ –≤ –æ–¥–Ω–æ–º —Å–æ–æ–±—â–µ–Ω–∏–∏:
1. **README.md** - –ø–æ–ª–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è
2. **requirements.txt** - –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
3. **Dockerfile** - Docker-–æ–±—Ä–∞–∑
4. **docker-compose.yml** - –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ü–∏—è
5. **run_tests.py** - —Ç–µ—Å—Ç-—Ä–∞–Ω–Ω–µ—Ä
6. **train_bc.py** - –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
7. **28 —Ñ–∞–π–ª–æ–≤** –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ `ne_qiki/`
8. **8 —Ç–µ—Å—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤** –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ `tests/`
9. **4 —Ñ–∞–π–ª–∞** –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ `tools/`
10. **1 —Ñ–∞–π–ª** –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ `monitoring/`

### ‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã:

```
ne_qiki/
‚îú‚îÄ‚îÄ core/ (7 —Ñ–∞–π–ª–æ–≤) ‚úÖ
‚îú‚îÄ‚îÄ models/ (2 —Ñ–∞–π–ª–∞) ‚úÖ
‚îú‚îÄ‚îÄ shared/ (2 —Ñ–∞–π–ª–∞) ‚úÖ
‚îú‚îÄ‚îÄ configs/ (1 —Ñ–∞–π–ª) ‚úÖ
‚îú‚îÄ‚îÄ schemas/ (3 —Ñ–∞–π–ª–∞) ‚úÖ
‚îú‚îÄ‚îÄ api/ (2 —Ñ–∞–π–ª–∞) ‚úÖ
‚îú‚îÄ‚îÄ benchmark/ (2 —Ñ–∞–π–ª–∞) ‚úÖ
‚îú‚îÄ‚îÄ datasets/ (2 —Ñ–∞–π–ª–∞) ‚úÖ
‚îú‚îÄ‚îÄ examples/ (2 —Ñ–∞–π–ª–∞) ‚úÖ
tests/ (8 —Ñ–∞–π–ª–æ–≤) ‚úÖ
tools/ (3 —Ñ–∞–π–ª–∞) ‚úÖ
monitoring/ (1 —Ñ–∞–π–ª) ‚úÖ
.github/workflows/ (1 —Ñ–∞–π–ª) ‚úÖ
```

### ‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏:

**–í—Å–µ –æ—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω—ã:**
- ‚úÖ Neural Engine —Å GRU+MLP –º–æ–¥–µ–ª—å—é
- ‚úÖ Feature Extractor —Å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π
- ‚úÖ Safety Shield —Å –∞–Ω—Ç–∏-—Ñ–ª–∞–ø–ø–∏–Ω–≥–æ–º
- ‚úÖ Proposal Evaluator
- ‚úÖ NATS Logger
- ‚úÖ Terminal Dashboard
- ‚úÖ Prometheus Metrics
- ‚úÖ Health Check API
- ‚úÖ Dataset Generator
- ‚úÖ ONNX Export –∏ –±–µ–Ω—á–º–∞—Ä–∫–∏–Ω–≥
- ‚úÖ –ü–æ–ª–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
- ‚úÖ Docker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∏–∑–∞—Ü–∏—è

### ‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Ä–æ–≤–Ω–µ–π:

**–£—Ä–æ–≤–µ–Ω—å 1:** ‚úÖ –†–µ–∞–ª–∏–∑–æ–≤–∞–Ω –ø–æ–ª–Ω–æ—Å—Ç—å—é
**–£—Ä–æ–≤–µ–Ω—å 2:** ‚úÖ –†–µ–∞–ª–∏–∑–æ–≤–∞–Ω –ø–æ–ª–Ω–æ—Å—Ç—å—é  
**Terminal Dashboard:** ‚úÖ –†–µ–∞–ª–∏–∑–æ–≤–∞–Ω –ø–æ–ª–Ω–æ—Å—Ç—å—é

### üì¶ –ì–æ—Ç–æ–≤–Ω–æ—Å—Ç—å –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é:

- ‚úÖ –í—Å–µ —Ñ–∞–π–ª—ã –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã
- ‚úÖ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞ —Å–æ–±–ª—é–¥–µ–Ω–∞
- ‚úÖ –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –ø–æ–ª–Ω–∞—è
- ‚úÖ –¢–µ—Å—Ç—ã –≤–∫–ª—é—á–µ–Ω—ã
- ‚úÖ Docker-—Ñ–∞–π–ª—ã –≥–æ—Ç–æ–≤—ã
- ‚úÖ CI/CD pipeline –≤–∫–ª—é—á–µ–Ω

**–ü—Ä–æ–µ–∫—Ç –ø–æ–ª–Ω–æ—Å—Ç—å—é –≥–æ—Ç–æ–≤ –∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—é –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é!** üéâ